# DS_DA_ML_HSE
Репозиторий создан для демонстрации домашних работ и семинаров в рамках курса "Анализ данных и машинное обучение".

## Структура репозитория

  - **solution.ipynb**: Задача заключается в добавлении новых метрик для KNN и сверку с встроенным алгоритмом `scikit-learn`
  - **solution_2.ipynb**: Задача заключается в добавлении HuberLoss для линейной регрессии, подборе гипермараметров и сравнении с HuberRegressor из `scikit-learn`
  - **solution_3.ipynb**: Задача заключается в добавлении регуляризации Лассо(L1) и Ридж(L2), подборе гипермараметров и сравнении с Logregress с параметром penalty='l1' | penalty='l2' из `scikit-learn`
  - **heart**: folder с данными для задания 3
  - **automobile**: folder с данными для задания 2

## Задача 1: Метрики для KNN**

### Описание задачи
В этой задаче необходимо добавить известные метрики (дистанции), аналогично Евклидовому, чтобы посмотреть на их качество. 
Реализация каждой из метрик доступны по [ссылке](https://habr.com/ru/articles/801885/).

Задача включает в себя:
- Загрузку и предварительную обработку данных.
- Реализацию дополнительных метрик для класса KNN
### Используемые инструменты:
- `pandas`: для работы с данными.
- `sckikit-learn`: для работы с алгоритмами и данными.


## Задача 2: HuberLoss

### Описание задачи
В этой задаче необходимо реализовать функциюю потерь Хубера (HuberLoss) и сравнить её с базовой функцией потери, а так же с встроенным HuberRegressor 

### Используемые инструменты:
- `pandas`: для работы с данными.
- `sckikit-learn`: для работы с алгоритмами и данными.


## Задача 3: L1 | L2 regularization

### Описание задачи
В этой задаче необходимо реализовать регуляризацию Лассо и Ридж (L1 | L2) для исходного класса Log. regres. и сравнить с встроенным алгоритмом и параметром penalty = l1 | l2 + подбором гиперпараметров.

### Используемые инструменты:
- `pandas`: для работы с данными.
- `sckikit-learn`: для работы с алгоритмами и данными.